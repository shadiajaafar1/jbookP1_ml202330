{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución Parcial Práctico 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import mglearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer: (KNN, LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La métrica de mayor importancia para la clasificación de cancer es recall puesto que se quiere limitar el número de falsos negativos y predecir con mayor presición los casos de cáncer positivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) GridSearchCV y Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabla de resultados:\n",
      "          Precision    Recall  F1-score       AUC\n",
      "Model                                            \n",
      "KNN        0.955556  0.955556  0.955556  0.940042\n",
      "Logistic   0.965517  0.933333  0.949153  0.938365\n"
     ]
    }
   ],
   "source": [
    "#Modelo de KNN----------------------------------------------------\n",
    "pipe_knn = Pipeline([\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid_knn = {\n",
    "    'knn__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(pipe_knn, param_grid=param_grid_knn, cv=5)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "y_pred_knn = grid_knn.predict(X_test)\n",
    "\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "auc_knn = roc_auc_score(y_test, y_pred_knn)\n",
    "\n",
    "results_knn = pd.DataFrame({\n",
    "    'Model': ['KNN'],\n",
    "    'Precision': [precision_knn],\n",
    "    'Recall': [recall_knn],\n",
    "    'F1-score': [f1_knn],\n",
    "    'AUC': [auc_knn]\n",
    "})\n",
    "\n",
    "# Modelo de regresión logística---------------------------------------------------------\n",
    "pipe_logistic = Pipeline([\n",
    "    (\"logistic\", LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid_logistic = {\n",
    "    'logistic__C': [0.1, 1.0, 10.0, 100, 1000]\n",
    "}\n",
    "\n",
    "grid_logistic = GridSearchCV(pipe_logistic, param_grid=param_grid_logistic, cv=5)\n",
    "grid_logistic.fit(X_train, y_train)\n",
    "y_pred_logistic = grid_logistic.predict(X_test)\n",
    "\n",
    "precision_logistic = precision_score(y_test, y_pred_logistic)\n",
    "recall_logistic = recall_score(y_test, y_pred_logistic)\n",
    "f1_logistic = f1_score(y_test, y_pred_logistic)\n",
    "auc_logistic = roc_auc_score(y_test, y_pred_logistic)\n",
    "\n",
    "results_logistic = pd.DataFrame({\n",
    "    'Model': ['Logistic'],\n",
    "    'Precision': [precision_logistic],\n",
    "    'Recall': [recall_logistic],\n",
    "    'F1-score': [f1_logistic],\n",
    "    'AUC': [auc_logistic]\n",
    "})\n",
    "\n",
    "results_combined = pd.concat([results_knn, results_logistic])\n",
    "results_combined.set_index('Model', inplace=True)\n",
    "\n",
    "print(\"\\nTabla de resultados:\")\n",
    "print(results_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Precision    Recall  F1-score       AUC\n",
      "0                  KNN   0.955556  0.955556  0.955556  0.940042\n",
      "1  Logistic Regression   0.988235  0.933333  0.960000  0.957233\n"
     ]
    }
   ],
   "source": [
    "best_knn_score = -1\n",
    "best_knn_parameters = {}\n",
    "\n",
    "best_lr_score = -1\n",
    "best_lr_parameters = {}\n",
    "\n",
    "for neighbors in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "    for weights in ['uniform', 'distance']:\n",
    "        knn = KNeighborsClassifier(n_neighbors=neighbors, weights=weights)\n",
    "        scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "        score = np.mean(scores)\n",
    "        if score > best_knn_score:\n",
    "            best_knn_score = score\n",
    "            best_knn_parameters = {'neighbors': neighbors, 'weights': weights}\n",
    "            best_knn_model = knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = best_knn_model.predict(X_test)\n",
    "\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "auc_knn = roc_auc_score(y_test, y_pred_knn)\n",
    "\n",
    "for c in [0.1, 1.0, 10.0, 100, 1000]:\n",
    "    lr = LogisticRegression(C=c, max_iter=1000)\n",
    "    scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "    score = np.mean(scores)\n",
    "    if score > best_lr_score:\n",
    "        best_lr_score = score\n",
    "        best_lr_parameters = {'C': c}\n",
    "        best_lr_model = lr.fit(X_train, y_train)\n",
    "        \n",
    "y_pred_lr = best_lr_model.predict(X_test)\n",
    "\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "auc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['KNN', 'Logistic Regression'],\n",
    "    'Precision': [precision_knn, precision_lr],\n",
    "    'Recall': [recall_knn, recall_lr],\n",
    "    'F1-score': [f1_knn, f1_lr],\n",
    "    'AUC': [auc_knn, auc_lr]\n",
    "})\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se puede observar que en general los modelos clasifican bien las muestras positivas de cancer. Veamos con más detalle las métricas de cada modelo:\n",
    "**KNN**\n",
    "- Precisión (0.955556): el 95.56% de las muestras clasificadas como positivas por el modelo KNN eran realmente positivas.\n",
    "- Recall (0.955556): el 95.56% de todas las muestras positivas en el conjunto de datos fueron identificadas correctamente por el modelo.\n",
    "- F1-score (0.955556): hay un buen equilibrio entre precisión y recall.\n",
    "- AUC (0.940042): el modelo tiene una buena capaciedad discriminativa.\n",
    "\n",
    "**Regresión Logística**\n",
    "- Precisión (0.965517): el 96.55% de las muestras clasificadas como positivas por el modelo de regresión logística eran realmente positivas.\n",
    "- Recall (0.933333): el 93.33% de todas las muestras positivas en el conjunto de datos fueron identificadas correctamente por el modelo.\n",
    "- F1-score (0.949153): hay un buen equilibrio entre precisión y recall.\n",
    "- AUC (0.938365): el modelo tiene una buena capacidad de discriminación, aunque ligeramente menor que el modelo KNN.\n",
    "\n",
    "En conclusión, dado que la nuestra métrica de interés es *recall* puesto que nos interesa que el modelo tenga una buena capacidad de clasificar las muestras positivas del conjunto de datos, se selecciona el modelo **KNN** ya que es el modelo con el recall más alto. Esto indica que es capaz de identificar más muestras positivas de cáncer de mama del conjunto de datos, lo cual es fundamental para que los casos positivos no pasen por alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing: (LinearRegression, Ridge, Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) GridSearchCV y Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabla de resultados:\n",
      "                      MAPE      RMSE       R^2\n",
      "Model                                         \n",
      "LinearRegression  0.154947  5.662962  0.607472\n",
      "Ridge             0.140119  4.308045  0.772834\n",
      "Lasso             0.163203  5.496564  0.630201\n"
     ]
    }
   ],
   "source": [
    "# Modelo de regresión lineal---------------------------------------------------------\n",
    "linear = LinearRegression()\n",
    "\n",
    "param_grid_linear = {\n",
    "}\n",
    "\n",
    "grid_linear = GridSearchCV(linear, param_grid=param_grid_linear, cv=5)\n",
    "grid_linear.fit(X_train, y_train)\n",
    "y_pred_linear = grid_linear.predict(X_test)\n",
    "\n",
    "mape_linear = mean_absolute_percentage_error(y_test, y_pred_linear)\n",
    "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "results_linear = pd.DataFrame({\n",
    "    'Model': ['LinearRegression'],\n",
    "    'MAPE': [mape_linear],\n",
    "    'RMSE': [rmse_linear],\n",
    "    'R^2': [r2_linear]\n",
    "})\n",
    "\n",
    "# Modelo Ridge--------------------------------------------------------------------------\n",
    "ridge = Ridge()\n",
    "\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1.0, 10.0, 100],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "}\n",
    "\n",
    "grid_ridge = GridSearchCV(ridge, param_grid=param_grid_ridge, cv=5)\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = grid_ridge.predict(X_test)\n",
    "\n",
    "mape_ridge = mean_absolute_percentage_error(y_test, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "results_ridge = pd.DataFrame({\n",
    "    'Model': ['Ridge'],\n",
    "    'MAPE': [mape_ridge],\n",
    "    'RMSE': [rmse_ridge],\n",
    "    'R^2': [r2_ridge]\n",
    "})\n",
    "\n",
    "# Modelo Lasso-----------------------------------------------------------------------------\n",
    "lasso = Lasso()\n",
    "\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.1, 1.0, 10.0, 100]\n",
    "}\n",
    "\n",
    "grid_lasso = GridSearchCV(lasso, param_grid=param_grid_lasso, cv=5)\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = grid_lasso.predict(X_test)\n",
    "\n",
    "mape_lasso = mean_absolute_percentage_error(y_test, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "results_lasso = pd.DataFrame({\n",
    "    'Model': ['Lasso'],\n",
    "    'MAPE': [mape_lasso],\n",
    "    'RMSE': [rmse_lasso],\n",
    "    'R^2': [r2_lasso]\n",
    "})\n",
    "\n",
    "\n",
    "results_combined = pd.concat([results_linear, results_ridge, results_lasso])\n",
    "results_combined.set_index('Model', inplace=True)\n",
    "\n",
    "print(\"\\nTabla de resultados:\")\n",
    "print(results_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model      MAPE      RMSE       R^2\n",
      "0  Linear Regression  0.154947  5.662962  0.607472\n",
      "1              Ridge  0.140289  4.313987  0.772207\n",
      "2              Lasso  0.163203  5.496564  0.630201\n"
     ]
    }
   ],
   "source": [
    "best_linear_score = -1\n",
    "best_linear_parameters = {}\n",
    "\n",
    "best_ridge_score = -1\n",
    "best_ridge_parameters = {}\n",
    "\n",
    "best_lasso_score = -1\n",
    "best_lasso_parameters = {}\n",
    "\n",
    "#Regresión lineal------------------------------------------------------\n",
    "linear = LinearRegression()\n",
    "scores = cross_val_score(linear, X_train, y_train, cv=5)\n",
    "best_linear_score = np.mean(scores)\n",
    "best_linear_model = linear.fit(X_train, y_train)\n",
    "\n",
    "y_pred_linear = best_linear_model.predict(X_test)\n",
    "\n",
    "mape_linear = mean_absolute_percentage_error(y_test, y_pred_linear)\n",
    "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "\n",
    "#Regresión Ridge------------------------------------------------------\n",
    "for alpha in [0.1, 1.0, 10.0, 100]:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(ridge, X_train, y_train, cv=5)\n",
    "    score = np.mean(scores)\n",
    "    if score > best_ridge_score:\n",
    "        best_ridge_score = score\n",
    "        best_ridge_parameters = {'alpha': alpha}\n",
    "        best_ridge_model = ridge.fit(X_train, y_train)\n",
    "        \n",
    "y_pred_ridge = best_ridge_model.predict(X_test)\n",
    "\n",
    "mape_ridge = mean_absolute_percentage_error(y_test, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "#Regresión Lasso-------------------------------------------------------\n",
    "for alpha in [0.1, 1.0, 10.0, 100]:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    scores = cross_val_score(lasso, X_train, y_train, cv=5)\n",
    "    score = np.mean(scores)\n",
    "    if score > best_lasso_score:\n",
    "        best_lasso_score = score\n",
    "        best_lasso_parameters = {'alpha': alpha}\n",
    "        best_lasso_model = lasso.fit(X_train, y_train)\n",
    "        \n",
    "y_pred_lasso = best_lasso_model.predict(X_test)\n",
    "\n",
    "mape_lasso = mean_absolute_percentage_error(y_test, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Ridge', 'Lasso'],\n",
    "    'MAPE': [mape_linear, mape_ridge, mape_lasso],\n",
    "    'RMSE': [rmse_linear, rmse_ridge, rmse_lasso],\n",
    "    'R^2': [r2_linear, r2_ridge, r2_lasso]\n",
    "})\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primera vista se puede observar que los modelos tienen un ajuste aceptable. Veamos cada métrica por separado:\n",
    "\n",
    "- MAPE: el modelo de Ridge Regression tiene el menor error absoluto medio porcentual (0.140), seguido por el modelo de Linear Regression (0.155) y el modelo de Lasso Regression (0.163). Esto sugiere que el modelo de Ridge es el más preciso en términos de la diferencia entre las predicciones y los valores reales.\n",
    "\n",
    "- RMSE:el modelo de Ridge Regression tiene el menor error cuadrático medio (4.308), seguido por el modelo de Linear Regression (5.663) y el modelo de Lasso Regression (5.497). Esto sugiere que el modelo de Ridge tiene la menor dispersión de errores.\n",
    "\n",
    "- R²: el modelo de Ridge Regression tiene el R² más alto (0.773), seguido por el modelo de Lasso Regression (0.630) y el modelo de Linear Regression (0.607). Esto sugiere que el modelo de Ridge tiene el mejor ajuste, explicando más varianza en los datos en comparación con los otros modelos.\n",
    "\n",
    "En resumen, el modelo **Ridge** es el mejor modelo de los 3, ya que tiene los mejores MAPE y RMSE, y el más alto R^2, lo que sugiere una mayor precisión y capacidad de ajuste con respecto a los otros modelos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
